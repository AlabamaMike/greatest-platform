"""Speech-to-text engine using Whisper."""

import time
from typing import List, Optional
from fastapi import UploadFile
import io

from app.core.model_manager import model_manager
from app.utils.logger import logger
from app.models.schemas import (
    SpeechToTextResponse,
    WordTimestamp,
)


class SpeechEngine:
    """Speech recognition and transcription engine."""

    def __init__(self):
        """Initialize speech engine."""
        self.whisper_pipeline = None
        self._initialized = False

    async def initialize(self) -> bool:
        """Initialize the speech engine."""
        try:
            # In production, load Whisper model:
            # await model_manager.load_model("openai/whisper-large-v2", "pipeline")
            # self.whisper_pipeline = model_manager.get_pipeline("openai/whisper-large-v2")

            self._initialized = True
            logger.info("âœ… Speech engine initialized")
            return True

        except Exception as e:
            logger.error(f"Failed to initialize speech engine: {e}")
            return False

    async def transcribe(
        self,
        audio: UploadFile,
        language: Optional[str] = None
    ) -> SpeechToTextResponse:
        """
        Transcribe speech to text.

        Args:
            audio: Audio file
            language: Language code (optional, auto-detect if not provided)

        Returns:
            Transcription result
        """
        try:
            # Read audio file
            contents = await audio.read()

            if self.whisper_pipeline:
                # Use real Whisper model
                result = self.whisper_pipeline(
                    contents,
                    return_timestamps="word"
                )

                transcription = result["text"]
                detected_language = result.get("language", language or "en")
                confidence = 0.91

                # Extract word timestamps if available
                words = []
                if "chunks" in result:
                    for chunk in result["chunks"]:
                        words.append(WordTimestamp(
                            word=chunk["text"],
                            start=chunk["timestamp"][0],
                            end=chunk["timestamp"][1],
                            confidence=0.90
                        ))

            else:
                # Mock implementation
                transcription = "This is a mock transcription. In production, this would use Whisper for accurate speech-to-text conversion."
                detected_language = language or "en"
                confidence = 0.75
                words = self._mock_word_timestamps(transcription)

            # Calculate duration (mock)
            duration_seconds = 45.0

            return SpeechToTextResponse(
                filename=audio.filename or "unknown",
                transcription=transcription,
                language=language or detected_language,
                detected_language=detected_language,
                confidence=confidence,
                duration_seconds=duration_seconds,
                words=words if words else None,
                model="whisper-large-v2"
            )

        except Exception as e:
            logger.error(f"Speech transcription failed: {e}")
            return SpeechToTextResponse(
                filename=audio.filename or "unknown",
                transcription=f"[Transcription error: {str(e)}]",
                language=language or "en",
                detected_language="unknown",
                confidence=0.0,
                duration_seconds=0.0,
                model="error"
            )

    def _mock_word_timestamps(self, transcription: str) -> List[WordTimestamp]:
        """Generate mock word timestamps."""
        words = transcription.split()
        timestamps = []
        current_time = 0.0

        for word in words:
            duration = len(word) * 0.1  # Rough estimate
            timestamps.append(WordTimestamp(
                word=word,
                start=current_time,
                end=current_time + duration,
                confidence=0.88
            ))
            current_time += duration + 0.2  # Add pause

        return timestamps


# Global speech engine instance
speech_engine = SpeechEngine()
